# Speech → VAD → Whisper
## Микрофонная расшифровка речи, которая вырастает в AI‑помощника

Это компактный, но амбициозный Python‑проект для реального времени: он слушает микрофон, находит фразы через **WebRTC VAD** и отправляет их в **Whisper** для распознавания текста.  
Сегодня — быстрый и чистый speech‑to‑text пайплайн. Завтра — база для **AI‑помощника**, который понимает, что вы сказали, и сразу помогает действовать.

---

## Как это работает

1. `sounddevice` читает аудио с микрофона чанками (фреймами) фиксированного размера.
2. Каждый фрейм:
   - пишется в кольцевой буфер (история последних N секунд) (`RingBuffer`)
   - проверяется `webrtcvad` на “speech / not speech”
3. `SpeechDetector` решает, когда **начать** запись фразы и когда **закончить**:
   - старт: `START_SPEECH_FRAMES` подряд фреймов с речью
   - стоп: `END_SILENCE_FRAMES` подряд тишины
   - добавляется небольшой **pre-roll** (аудио “до старта” из ring buffer)
4. После завершения фразы аудио конвертируется в `float32` и передаётся в Whisper `transcribe(...)`, текст печатается в консоль.

---

## Куда это растёт

Этот проект — фундамент голосового **AI‑помощника**:
- понимание речи в реальном времени
- быстрые ответы и подсказки
- интеграции с задачами, календарём, заметками, поиском и ботами
- приватный локальный режим или облако — на ваш выбор

---

## Требования

- Python 3.9+ (желательно 3.10+)
- Зависимости:
  - `numpy`
  - `sounddevice`
  - `webrtcvad`
  - `openai-whisper` (пакет `whisper`) + зависимости (`torch`, и т.п.)

> `sounddevice` использует PortAudio. На Linux/macOS иногда нужно поставить системную библиотеку PortAudio, иначе устройство ввода не откроется.

---

## Установка

### Быстрый вариант
```bash
pip install numpy sounddevice webrtcvad openai-whisper
```

---

## Запуск

```bash
python main.py
```

- В консоли появится `Start...`
- Говорите фразами: после паузы (тишины) программа выведет распознанный текст
- Остановить: `Ctrl + C`

---

## Настройки (`config.py`)

Все основные параметры лежат в `config.py`.

### Аудио
- `SAMPLE_RATE = 16000` — частота дискретизации
- `CHANNELS = 1` — моно
- `FRAME_MS = 20` — размер фрейма (WebRTC VAD любит 10/20/30 мс)
- `FRAME_SAMPLES` — вычисляется автоматически

### Ring buffer (история)
- `BUF_SEC = 2` — сколько секунд истории хранить
- `BUF_SAMPLES` — размер буфера в сэмплах

### VAD
- `VAD_MODE = 2` — агрессивность (0 мягче, 3 жёстче)
- `START_SPEECH_FRAMES = 3` — сколько подряд “speech” для старта фразы
- `END_SILENCE_FRAMES = 40` — сколько подряд “silence” для завершения фразы  
  > При `FRAME_MS=20` это ~800 мс тишины.

### Pre-roll (звук до старта)
- `PRE_ROLL_MS = 300` — сколько миллисекунд добавить “до”
- `PRE_SAMPLES` — вычисляется автоматически

### Whisper
- `LANGUAGE = "ru"`
- `WHISPER_MODEL = "base"` (но см. заметку ниже)

---

## Структура проекта

- **`main.py`** — точка входа: аудиострим, очередь фреймов, VAD, вызов Whisper  
- **`RingBuffer.py`** — кольцевой буфер для хранения последних N сэмплов  
- **`SpeechDetector.py`** — логика “старт/стоп фразы” + pre-roll и сбор фреймов в единый массив  
- **`config.py`** — все параметры проекта  

---

## Быстрая настройка качества

- Если **обрезает начало фраз** → увеличьте `PRE_ROLL_MS` или уменьшите `START_SPEECH_FRAMES`
- Если **слишком поздно завершает фразу** → уменьшите `END_SILENCE_FRAMES`
- Если **часто “ловит шум как речь”** → увеличьте `VAD_MODE` до 3 и/или увеличьте `START_SPEECH_FRAMES`
- Если **пропускает речь** → уменьшите `VAD_MODE` (например, 1–2)

---

## Известные замечания по текущему коду

- В `config.py` есть `WHISPER_MODEL`, но в `main.py` модель загружается жёстко как `"base"`:  
  `model = whisper.load_model("base")`  
  Если хотите управлять из конфига — замените на `whisper.load_model(cfg.WHISPER_MODEL)`.

- В `main.py` есть `save_event` и поток `wait_enter()`, но событие дальше нигде не используется (сейчас это “заготовка”).

---

## Troubleshooting

**1) Ошибка устройства ввода / нет микрофона**  
Проверьте, что микрофон доступен системе, и что `sounddevice` видит input-device по умолчанию.

**2) Ничего не печатает**  
Если “тишина” не детектится — попробуйте:
- уменьшить `END_SILENCE_FRAMES`
- изменить `VAD_MODE`
- убедиться, что реально идёт звук в микрофон (уровень, правильное устройство)

**3) Очень медленно**  
Whisper “base” может быть тяжёлым на CPU. Попробуйте меньшую модель (например, `tiny`) или используйте GPU (если доступно).

pyinstaller --noconsole --onefile --add-data "C:\\Users\\Adam\\Documents\\Work\\LarbCorp\\NeuroCorp\\AI-Assistant\\model\\vosk-model-small-ru-0.22;model/vosk-model-small-ru-0.22" --add-data "C:\\Users\\Adam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\vosk\\libvosk.dll;vosk" --add-data "C:\\Users\\Adam\\Documents\\Work\\LarbCorp\\NeuroCorp\\AI-Assistant\\icon.ico;." main.py
